ğŸ§  RAG-Based Retrieval System with FAISS & DeepSeek LLM







ğŸ“¢ A powerful, scalable Retrieval-Augmented Generation (RAG) system using FAISS and DeepSeek LLM.ğŸ”¹ Ideal for knowledge-based Q&A, document retrieval, and AI chatbots.ğŸ”¹ Supports PDFs and web page processing with fast FAISS-based retrieval.

ğŸ“œ Table of Contents

ğŸ“Œ Features

ğŸš€ Installation

ğŸ“‚ Project Structure

ğŸ› ï¸ Usage

ğŸ”§ Configuration

âš¡ Performance Optimizations

ğŸ› ï¸ Troubleshooting

ğŸ›¡ï¸ License

ğŸ“Œ Contributors

ğŸ“§ Contact

ğŸ“Œ Features

âœ… Retrieval-Augmented Generation (RAG) â€“ Uses FAISS for context-aware query answering.âœ… Multi-Document Support â€“ Processes PDFs and web pages.âœ… DeepSeek-Style Prompting â€“ Ensures structured, fact-based responses.âœ… Fast & Scalable Retrieval â€“ FAISS enables rapid similarity search.âœ… Cosine Similarity Ranking â€“ Retrieves the most relevant chunks.âœ… Cleans LLM Output â€“ Removes unwanted artifacts like <think>.

ğŸš€ Installation

1ï¸âƒ£ Clone the Repository

git clone https://github.com/yourusername/RAG_Project.git
cd RAG_Project

2ï¸âƒ£ Install Dependencies

Ensure you have Python 3.8+ installed, then run:

pip install -r requirements.txt

If you don't have a requirements.txt, manually install:

pip install numpy faiss-cpu aiohttp PyPDF2 beautifulsoup4 ollama

3ï¸âƒ£ Set Up Directory Structure

Create the necessary folders:

mkdir -p embeddings data

ğŸ“‚ Project Structure

ğŸ“¦ RAG_Project
â”œâ”€â”€ ğŸ“‚ embeddings/               # Stores generated embeddings
â”œâ”€â”€ ğŸ“‚ data/                     # Stores input PDF & web page files
â”œâ”€â”€ ğŸ“œ embedding_generation.py   # Generates embeddings from PDFs & HTML
â”œâ”€â”€ ğŸ“œ query_retrieval.py        # Retrieves and answers queries
â”œâ”€â”€ ğŸ“œ README.md                 # Documentation

ğŸ› ï¸ Usage

ğŸ”¹ Step 1: Generate Embeddings

Run embedding_generation.py to process PDFs and web content:

python embedding_generation.py

This script:

Extracts text from PDFs and HTML.

Splits text into chunks.

Generates embeddings for each chunk.

Stores embeddings in FAISS for fast retrieval.

ğŸ”¹ Step 2: Retrieve Answers

Run query_retrieval.py to query the stored knowledge base:

python query_retrieval.py

You'll be prompted to enter a query:

Enter your query (or type 'exit' to quit): What is the impact of inflation?

ğŸ”¹ The system will:
1ï¸âƒ£ Compute the query embedding.2ï¸âƒ£ Search FAISS for the most relevant chunks.3ï¸âƒ£ Use DeepSeek LLM to generate an answer.4ï¸âƒ£ Return a clean, structured response.

ğŸ”§ Configuration

Modify model settings in both scripts:

# Constants
EMBEDDINGS_DIR = "embeddings"  
DATA_FOLDER = "data"  
LLM_MODEL = "deepseek-r1:14b"  
EMBEDDING_MODEL = "nomic-embed-text"  

To change how many retrieved chunks are used for answering:

top_k = 3  # Change this to retrieve more or fewer chunks

âš¡ Performance Optimizations

âœ… Uses FAISS for fast similarity search.âœ… Async web scraping speeds up data extraction.âœ… Text chunking ensures better LLM processing.âœ… Cosine similarity ranking improves accuracy.

ğŸ› ï¸ Troubleshooting

Issue

Solution

âŒ "No valid embeddings found."

Run embedding_generation.py before querying.

âŒ "ModuleNotFoundError: No module named 'faiss'"

Install FAISS using pip install faiss-cpu.


ğŸ›¡ï¸ License

This project is licensed under the MIT License.

ğŸ“Œ Contributors

ğŸ’¡ Your Name - Project CreatorğŸ’¡ Other Contributor Name - Contributor

Feel free to contribute! Open a Pull Request (PR) or report issues in the Issue Tracker.

ğŸ“§ Contact

For any issues or improvements, contact me at:ğŸ“§ your_email@example.comğŸ”— GitHub: yourusername

ğŸŒŸ Support

â­ If you like this project, give it a star on GitHub! â­ğŸ“¢ Share it with others who might find it useful.

